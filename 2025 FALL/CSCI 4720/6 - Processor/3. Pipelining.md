```table-of-contents
```

# Pipelining
- longest delay determines clock period
	- critical path: load instruction
	- instruction mem -> reg file -> ALU -> data mem -> reg file
- Not feasible to vary period for diff instructions
- Violates design principle
	- making common case fast
- we will improve performance by pipelining
## Pipelining Analogy
- Pipelined laundry: overlapping execution
	- Parallelism improves performance
	- Washing, drying, folding, and putting away

### Key principles:
-   **Divide a task into independent sequential stages.**
-   **Assign each stage to a distinct processing component.**
-   **Execute different stages of multiple tasks concurrently using these dedicated resources.**

## MIPS Pipeline Steps
The classic MIPS pipeline consists of five stages:

1. **Instruction Fetch (IF):** Fetch the instruction from memory.
2. **Instruction Decode (ID):**
    - Figure out the opcode and operands.
    - Set correct control fields for the circuit.
    - Extract register numbers to read the register file.
    - All these steps occur in one stage.
    - Sign extension of immediate vals
    - Calc potential branch target addresses
3. **Execute (EX):** Perform arithmetic/logical operation based on the instruction's opcode using the ALU.
4. **Memory Access (MEM):** Read/write data from/to memory (if required by the instruction).
5. **Write Back (WB):** Write the result back to a register.
    - Not needed if the instruction only reads (e.g., store instruction).
    - Required for load/store instructions (for a load) or arithmetic results.

# Pipeline Performance
- Assume time for stages is
	- 100ps for reg read/write
	- 200ps for other stages
- compare pipelined datapath w/ single-cycle datapath
![[Pipeline ex comparison table.png]]
![[Pipeline Performance ex charts.png]]

## Pipeline Speedup
- MIPS

- All instructions 32-bits
	- makes it easier to fetch instruction from mem
	- just +4
	- This is diff for x6 insturction set, where instructions are variable bit count
		- size not fixed
- Instruction Formats for MIPS are few and regular 
	- can decode and read reg in one step
- Load/Store addressing
	- Can calc address in 3rd stage, access mem in 4th stage
- Alignment of mem operands

# Hazards
- Situations that prevent starating next instruction in next cycle
- if you can't start it, then performance issues

1. Structure Hazards
2. Data hazards
3. Control hazards

## Structure Hazards
- Conflict for use of a resource
	- if 2 instructions need to access same resource, and resource can only serve one instruction,
		- STRUCTURE HAZARD

- In MIPS pipeline w/ single mem
	- Load/Store requires data access
	- Instruction fetch would have to stall for that cycle
		- Would cause pipeline "bubble"

- Hence, pipelined datapaths require separate instruction/data memories
	- Or separate instruction/data caches

## Data Hazards
- An instruction depends on completion of data access by a previous instruction
```
add $s0, $t0, $t1
sub $t2, $s0, $t3
```
![[Data Hazards Ex.png]]
- The `sub` instruction cannot execute correctly until `add` writes `$s0`. Without intervention, this would cause the `sub` instruction to stall, creating a pipeline bubble.
### Forwarding (aka Bypassing)
- Forwarding is hardware technique to mitigate data hazards 
- -> by providing result of an instruction to a dependent instruction _as soon as it's computed_, rather than waiting for it to be written back to the register file.

- **Mechanism:** Special data paths are added to the datapath to send results directly from an earlier stage
	- *Use result as soon as it is computed*
	- Don't wait for it to be stored in a register
- **Benefit:** Reduces stalls by allowing dependent instructions to proceed sooner.
- **Costs:** Requires extra connections in the datapath 
	- (additional hardware for these extra connections)
	- (multiplexers and control logic)

- w/o forwarding, then would have to wait for another cycle
- although it cannot completely remove bubble

### Load-Use Data Hazard
![[Load-Use Data Hazard.png]]

- Can't always avoid stalls by forwarding
	- if value not computed when needed
	- can't forward backward in time
![[Load-Use Data Haraz 2.png]]

### Reordering ocde to Avoid Pipeline Stall 1 (Software Solution)
![[Software Solution to avoid pipeline stall.png]]
- basically make sure to use a diff reg after immediate load instruction

## Check Yourself
![[Check Yourself - sequences.png]]

sequence 2:
- data hazard in 1st and 3rd instruction ($t1), cause of addi... why?
- use forwarding at first line add $t1, \$t0, \$t0 

## Control Hazards
- Branch determines flow of control
	- Fetching next instruction depends on branch outcome
	- Pipeline can't always fetch correct instruction
		- Still working on ID stage of branch
- In MIPS pipeline
	- Need to compare registers and compute target early in the pipeline
	- Add hardware to do it in ID stage

### Stall on Branch
- Wait until branch outcome determined before fetching next instruction
![[Stall on Branch ex.png]]

### Branch Prediction
- Longer pipelines can't readily determine branch outcome early
	- Stall penalty becomes unacceptable
- Predict outcome of branch
	- Only stall if prediction is wrong
- In MIPS pipeline
	- Can predict branches not taken
	- Fetch instruction after branch, with no delay

- **Can lead to PREDICTION FAILURE**
- most modern cpu has tuned prediction to be higher than 99%
- this is because cost of prediction failure is very high
	- why? b/c you have to clear the register storage inside of pipeline so following instruction can be fetched

- machine learning algorithms can be applied to predict branch outcome
### MIPS w/ Predict Not Taken
![[MIPS w Predict Not Taken.png]]
### More-Realistic Branch Prediction
- Branch Prediction can be classified into 2 types ->
#### Static Branch Prediction
- Based on typical branch behavior
- Example: Loop and If-statement branches
	- Predict backward branches taken
	- Predict forward branches not taken
#### Dynamic branch prediction
- Hardware measures actual branch behavior
	- E.g., record recent history of each branch
- Assume future behavior will continue the trend
	- When wrong, stall while re-fetching, and update history

# Pipeline Summary
- **THE BIG PICTURE**
- Pipelining improves performance by increasing instruction throughput
	- Executes multiple instructions in parallel
	- Each instruction ahs the same latency
- Subkect to hazards
	- Structure, data, control
- Instruction set design affects complexity of pipeline implementation

