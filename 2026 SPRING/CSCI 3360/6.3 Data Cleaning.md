```table-of-contents
```
# Review
- Stopped at Data cleaning

-  **Data Munging**
	- converting unorganized/unstructured data to structured
	- no scientific method
- *Handling Missing Data*
	- Strategies: 
		- dropping records
		- using global constant to fill up
			- fill with mean val
		- imputation, etc.
			- learn from vals and impute them

- This time, continue Data Cleaning process

# Intro
## Smooth Noisy Data
- data my be corrupted/inconsistent or noise present
- Strategies:
	- Removing outliers
	- resolve inconsistencies systematically

- Sometimes, outliers are important:
	- identifying RARE occurrences
	- and you want to learn the outlier 'patterns'

	- in data mining tasks, it is important
	- for normal data analysis, its not important

# Data Pre-Processing
- Cleaning
- Integration
- Transformation
- Reduction

## Data Integration
- only relevant for multiple data sources
- combines data from multiple sources into a coherent storage place (e.g., a single file or a database)
- schema integration, e.g., A.cust_id and B.cust_number
- Combining of metadata from diff sources

- **Detect and resolve data value conflicts**
	- diff representations or different scales/metrics
- **Address redundant data in data integration**
	- *Redundant data is commonly generated in the process of integrating multiple databases*
		- Same attribute with different names in different databases
		- "Derived" attributes
	- **Correlation analysis may detect instances of redundant data**


## Data Transformation
- Generalization
- Attribute
- Feature Creation
- 

### 1. Generalization
- Concept hierarchy climbing
	- A way to organize concepts defined in a knowledge domain
	- Multilevel organization of concepts
- **Ex: categorical variables**
-  ![[Drawing 2026-02-19 13.34.15.excalidraw]]
### 2. Discretization and Binarization
- **Discretization is the process of converting a continuous attribute into an original attribute**
- **Binarization maps a continuous or categorical attribute into one or more binary vars**

### 3. Attribute Transformation
- A func that **maps the entire set of vals** of a given attribute **to a new set of replacement vals**
	- **Simple funcs:** x^k, logx, e^x, |x|
	- **Normalization:**
		- Refers to various techniques to adjust to differences among attributes in terms of frequency of occurrence, mean, variance, range
		- Ex: Min-max
			- say age is 10-30
			- income 10k-50k
			- *if we normalize min to be 0, max to be 10, you **standardize** the values*
		- Z-score (standardization)
	- Decimal Scaling

### 4. Feature Creation
- create new attributes that can capture the important info in a data set much more efficiently than the original attributes

- 3 General Methods:
	- Feature extraction
		- Ex: Extracting edges from images
			- could use the features as something to train the model to learn
	- Feature Construction
		- Combining multiple features to create new features
	- Mapping data to new space
		- Ex: Fourier and wavelet analysis


## Data Reduction
- Obtains reduced representation of data set that is much smaller in volume yet produces same (or almost) analytical results
- Strategies:
	- Data Cube Aggregation
	- Dimensionality Reduction
	- Numerosity Reduction
	- Discretization and Concept Hierarchy generation

#### Data Cube Aggregation
- **Data Cube**: A multidimensional array used for data analysis.
- **Purpose**: Reduce data to a single entity of interest.
- **Method**: Focus on a specific object, then aggregate the data to a higher-level concept.
    - **Ex**: Aggregate sales by region or by month.
- **Benefit**: Good for summarizing data and identifying trends at different granularities.

### Dimensionality Reduction
- Feature selection (i.e., attribute subset selection):
	- probablity distribution of diff classes given vals for those feature sis as close as possible to original distribution given vals of all feats
	- reduce num of patterns in the patterns
	- easier to understand
- Heuristic methods (due to expon. num of choices):
	- step-wise forward selection
	- step-wise backward elimination
	- combining forward selection and backward elimination
	- decision-tree induction

#### Ex of Decision Tree Induction
- if tree can closely identify object w/o all the features, we reduce our attribute sets from initial attribute set

