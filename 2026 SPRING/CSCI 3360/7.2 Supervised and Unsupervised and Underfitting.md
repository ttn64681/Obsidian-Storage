```table-of-contents
```
# Review
- k

# Intro
- flexibility of models

# Supervised
- each observation of predictor measurement(s) xi,i = 1, ..., n there is an associated response measurement yi.
- We are to fit a model that relates to the predictors, with the aim of
	- accurately predicting the response for future observations **(prediction)** or 
	- better understanding the relationship b/w the response and the predictors **(inference)**

- will try to mimic the responses
# Unsupervised
- for every observation, i = 1, ..., n we observe vector of measurements xi but no associated response yi
- We can seek to understand the relationships b/w the vars or b/w the observations
	- Ex learning tool: cluster analysis

# Regression vs Classification Problems
- Types of variables:
	- Quantitative:
		- Takes nominal values
		- Ex:
			- person's age, height, income, value of a house, and price of a stock
	- Qualitative (categorical):
		- Ex:
			- classification problems
			- putting into bins

## Quality of Fit (Mean Squared Error)
- we don't want simple error summing:
- *Why?*
	- if you have error of +30 and -30, they cancel out, so mean error is 0, but our model is flawed. That is why we want MEAN SQUARED ERROR (MSE)
		- square cancels out the negative

- in regression setting, most commonly-used measure is Mean Squared Error
	MSE = 1/n SUM(i=1,n) [yi - ^f(xi)]^2
- We want to choose method that gives lowest test MSE, as opposed to lowest training MSE

## Model flexibility
- Orange line **(simple linear regression):**
	- an inflexible, fully parametrized model 
	- Cannot provide a good estimate of f(X)
	- Cannot overfit by modeling the noisy deviations of the data from f(X)
- Green line
	- overly flexible, nonparametric model
	- it can provide a good estimate f(X)
	- BUT it goes too far and overfits by modeling the noise

- the Orange line in second graph is u shape
- why is it u shape?
## Expected Test MSE
- obtained by repeatedly estimating f using large num of training sets, and tested each at x0
- In order to minimize the expected test error,
	- select a statistical learning method that simultaneously achieves low variance and low bias

- 3 components of MSE:
	- variance of model
	- bias of model
	- variance of error

- to lower, we get variance close to zero (variance is just positive)
- this causes orange line to get U shape


## Variance and Bias
- variance refers to amount by which ^f  ...
- bias refers to  ...

**Linear Regression fits**
- if the data points are more curved/parabolic, but linear regression is straight, this is HIGH BIAS
**Spline fits (3d curve)**
- comparatively, this would have LESS BIAS, but still makes error
- but still, since too flexbile, model will have HIGH VARIANCE

- either of these are bad models for us: we want LOW BIAS and LOW VARIANCE

## Bias-Variance Variance trade-off
- dotted line is irreducible error (lowest error we can get)
- non linear data distribution
- still a trade-off even with s curve model

### Sales Ex:
- y - sales
- x - tv advertising budget

- is there a relationship b/w advertising budget and sales?
	- **Exploratory Data Analysis**
- if there is association, how strong is relationship b/w advertising budget and sales?
- if there is, what is the strength of relationship
- How large is association b/w each medium and sales?

- How accurately can we predict future sales?
	- **Prediction**
- Is relationship linear?
- for given level of tv, radio, or newspaper advertising, determine prediction for sales and accuracy of prediction

- is there synergy among the advert media?
- in marketing, this is known as a synergy effect, while in statistics it is called an interaction effect