```table-of-contents
```
# Input, Output, Hidden Neurons
*   **Inputs and Outputs**: A neural network is designed to map a set of input features to a set of desired outputs. 
	* ex: a network can process 4 input features to predict 2 output values.

*   **Example: Predicting Age**
    *   **Goal**: Estimate a person's age.
    *   **Input Features (Determinants of Age)**: These are the data points fed into the network.
        *   Body weight
        *   Wrinkles (e.g., severity, quantity)
        *   Hair color (could be less reliable or "noisy" as a direct age indicator)
        *   50-yard dash time (proxy for physical fitness/agility, which can correlate with age)

##  **Learning Process (Weight Modification)**:
*   If predicted output is WRONG,  network adjusts its internal parameters, primarily the **weights**.
*   By modifying weights, the network learns to quantify the relative importance or **contribution of each input** to the final result. 
* A higher absolute weight magnitude for a given input suggests a stronger influence on the output.
* This happens over many training rounds **(epochs)** 

- epoch: 1 complete pass thru the entire training dataset

## Caveats
**Overfitting Problem:**
- if you have too large of a network (weights and neurons), but few data points,
	- the powerful model will only *remember* the data points but not internalize it and recognize the pattern behind them

## Activation Function
- We want activation functions so our neurons aren't LINEAR
	- we need to introduce non-linearity to our network
- so we append activation functions AFTER the linear neuron


# Types of Learning Tasks
## Supervised Learning
- Learn from labeled examples
- Each example is a pair consisting of an input object *(typically a vector)* and a desired output value (also called the supervisory signal)
- *More popular, more performant, and more capable than unsupervised*
- Self-supervised Learning:
	- 

## Unsupervised Learning
- Draw inferences from datasets consisting of input data w/o labeled responses
- Find hidden patterns or grouping in data
- Ex:
	- **K-means**
		- cluster data into k-clusters
		- network will find center of each cluster
		- and will find closest data to the center of the clusters, and categorize those data into that corresponding-closest cluster


## Types of Supervised Learning
### Regression:
- the target output is a real number or a whole vector of real numbers.
	- The price of a stock in 6 months time
	- The temperature at noon tomorrow

### Classification:
- target output is a class label
	- The simplest case is a choice b/w 1 and 0
	- We can also have multiple alternative labels

## How Supervised Learning Works
- start by choosing a model-class: y = f(x;W)
	- f, is a way of using some numerical params, W, to map each input vector, x, into a predicted output y
	- y - scalar/vector to represent the whole output
	- x: input vector
	- W: all the weights (and biases)

- Learning usually means **adjusting the params to reduce the discrepancy b/w the target output, t, on each training case and the actual output, y produced by the model.**
	- For regression, 1/2(y-t)^2 is often a sensible measure of the discrepancy
		- this is known as a "loss function", used to measure discrpancy
		- this specific form is called "squared error" and when averaged over dataset, it becomes mean squared error loss (MSE)
	- For classification, there are other measures that work better
		- e.g., cross-entropy loss

## How Unsupervised learning works
- Unsupervised learning aims to find hidden patterns, structures, or representations within input data without explicit output labels.
- Instead of learning a mapping from `x` to `y`, the goal is often to learn a function `f(x)` that transforms `x` into a new representation or identifies inherent groupings.
- Common approaches include:
    -   **Clustering**: Grouping similar data points together (e.g., K-means, as you noted). The model identifies the inherent clusters based on the data's features.
    -   **Dimensionality Reduction**: Reducing the number of input features while retaining important information (e.g., PCA, autoencoders). This can help visualize data or prepare it for other learning tasks.
    -   **Density Estimation**: Estimating the distribution of data within a given space.
- The "pretrained learning" concept often refers to training a model (like an autoencoder) in an unsupervised manner to learn useful features, which can then be used in a subsequent supervised task (e.g., using the encoder part of an autoencoder for feature extraction).

## Reinforcement Learning
- **Goal**: An agent learns to make a sequence of decisions in an environment to maximize a cumulative reward signal
	- <span style="background:#fff88f">"Learn to select an action to Maximize payoff"</span>
	- Learn policy thru rewards/penalties

- **Applications**: Robotics, game playing (e.g., AlphaGo), autonomous driving, resource management.
	- Alpha GO
	- Alpha Star
	- OpenAI Five (Dota 2)

- Powerful b/c:
	- current version of OpenAI Five has consumed 800 petaflop/s-days and experienced about 45k yrs of DOTA 2 self-play over 10 realtime months (up from about 10k years over 1.5 realtime months as of The International)

- In reinforcement learning, the output is an action or sequence of actions and the only supervisory signal is an **occasional scalar reward**
	- goal in selecting each action is to maximize the expected sum of future rewards
	- usually use a discount factor for delayed rewards so that we don't have to look too far into the future

- Reinforcement learning is difficult:
	- rewards are typically delayed so its hard to know where we went wrong (or right)

- **Key Components**:
    -   **Agent**: The learner or decision-maker.
    -   **Environment**: Everything outside the agent; the context in which the agent operates.
    -   **State (S)**: The current situation of the agent and environment.
    -   **Action (A)**: A move or decision made by the agent within the environment.
    -   **Reward (R)**: A numerical feedback signal from the environment indicating the desirability of an action taken in a given state. The agent's goal is to maximize the total accumulated reward over time.
    -   **Policy (Ï€)**: The strategy the agent uses to decide its next action given a state. It maps states to actions.
- **How it Works**:
    -   The agent observes the current state of the environment.
    -   Based on its policy, it takes an action.
    -   The environment transitions to a new state and provides a reward (positive or negative).
    -   The agent learns by trial and error, adjusting its policy over time to choose actions that lead to higher rewards in the long run.


# Components of a Dataset
![[Drawing 2026-01-21 17.16.51.excalidraw]]

## Three Sets of Data
- Training Set
	- A set of data used to train model
	- This is where model learns pattern, relationships, and features
	- This dataset is usually the alrgest portion of data, comprising around 60-80%
- Validation set
	- Helps in evaluating the model's performance during the training phase w/o being directly involved in training process
	- Typically, the validation set makes up about 10-20% of total data
	- Model's performance on the validation set is monitored to avoid overfitting or underfitting
- Testing set
	- Evaluate the final performance of the model after training. 
	- It acts as a completely independent and **unseen** set of data to assess how well the model generalizes to new data


# Different Types of Neural Networks
## Feed-forward Neural Networks
- **most common type of neural networks**
- first layer: input
- last layer: output
- **if more than 1 hidden (middle) layer, we call them "deep" neural networks**
- No directed cycles in graph

- Ex:
	- Multi-layer perceptron (MLP)
	- Convolutional Neural Network
	- Transformer (GPT)

### Universal Approximation Theorem
- Neural network can approximate any complex continuous function
- Only need one hidden layer
- contain sufficient number of neurons
- given appropriate activation function
- also holds true even the function has many inputs and outputs

## Multilayer Perception (MLP)
- Fully Connected (FC) Layer
	- Previous Layer's Neurons all connect to all the neurons in the hidden layer 

# Notes
# Vocab
- epoch
	- 1 complete pass thru the entire training dataset
- supervised learning
	- learn from labeled examples
- unsupervised learning
	- draw inferences from datasets consisting of input data without labeled responses
- reinforcement learning

- 



- feed-forward neural network