# Intro
- Inspired by biological vision system (Hubel & Wiesel experiment).
## Hubel & Wiesel Experiment
- Studied visual cortex; found neurons respond to specific features (edges) and operate hierarchically.

# Neural Basis of Visual Perception
- **Key Idea**: Visual system decomposes scenes into simple features processed hierarchically.
    - **Feature Detectors**: Neurons specialize (edges, colors).
    - **Hierarchical Processing**: Simple features combine into complex ones.
    - **Local Receptive Fields**: Neurons process small input regions.
- **Impact**: Inspired CNNs, significantly improving computer vision.
- **Early Example**: LeNet.

# LeNet
- A pioneering CNN.
- **Components**: Convolutional layers, subsampling (pooling) layers to reduce dimensions, followed by fully connected layers.

# Convolution Layer
- **Function**: Extracts features using learned filters.
- **Filter (Kernel)**: Small array of weights (e.g., 5x5x3 for RGB).
- **Scanning**: Filter slides over input (e.g., 32x32x3 image).
- **Output Feature Map (Activation Map)**:
    - Generated by summing element-wise products of filter and input patch.
    - Highlights the presence of a specific feature at a location.

## Filter -> Feature Map
- **One Filter**: Produces one feature map.
- **Multiple Filters**: A layer uses multiple filters, each producing a unique feature map.
    - Number of filters = Number of output channels.

## Conv Layer Example
- **Sliding Window**: Filter moves across input.
- **Channel Compatibility**: Filter depth must match input channels (e.g., 3 for RGB).
- **Input/Output**: Input = image/previous maps; Output = new feature maps.
- **Layer Progression**: Output maps become input for the next layer.
    - **Filter Depth Example**: If previous layer had 6 channels, filters are `3x3x6`.
- **Number of Filters**: Hyperparameter determining output depth.
- **Feature Specialization**: Each filter learns a specific feature (e.g., edge, texture).
- **Local Connectivity**: Neurons connect only to a small input region.

## ConvNet
- Deep network for grid-like data (images).
- **Architecture**: Sequence of Conv -> Activation -> Pooling layers, often ending with Fully Connected layers.

## Features at Different Layers
- **Hierarchy**: Early layers detect simple features (edges), deeper layers detect complex features (objects).
- **Progression**: Image -> Low-Level Features -> Mid-Level Features -> High-Level Features -> Classifier.

# Stride in Convolutional Layer
- **Stride**: Step size of the filter movement (e.g., 1 or 2 pixels).
- **Effect**: Larger stride reduces output spatial dimensions (width/height).
    - **Example**: 7x7 input, 3x3 filter. Stride 1 -> 5x5 output. Stride 2 -> 3x3 output.
- **Downsides of Large Stride**: Information loss at edges, reduced receptive field for subsequent layers.
- **Output Size Formula**: `floor((Input Size - Filter Size + 2*Padding) / Stride) + 1`

## Zero Padding
- **Purpose**: Controls output size, gives border pixels equal treatment.
    - Prevents feature maps from shrinking too fast.
- **Example**: 7x7 input, 3x3 filter, 1-pixel padding. Output with stride 1 is 7x7.
- **Effect**: `Padding = (Filter Size - 1) / 2` with `Stride = 1` preserves spatial dimensions.

# Size Calculation Example
- **Input**: 32x32x3
- **Layer**: 10 filters, 5x5x3 filter size, stride 1, padding 2.
- **Output Volume**: 32x32x10
    - `Output Dim = floor((32 - 5 + 2*2) / 1) + 1 = 32`
- **Parameters**: `(5 * 5 * 3 + 1 bias) * 10 filters = 760`
- **Computation Cost**: Proportional to `Output H * W * C_in * F_H * F_W * Num Filters`.

# Notes:
- **Number of Feature Maps**: Equals the number of filters.
- **Layer Flow**: Output channels of layer N become input channels of layer N+1.
    - **Filter Depth**: Must match input channels (e.g., `3x3x6` filter for 6 input channels).
- **Number of Filters**: Hyperparameter controlling layer capacity.

# Test (Conceptual)
- **Output Size**: Driven by `(Input - Filter + 2*Pad) / Stride + 1`. Padding is key for border pixels and size control.
- **Parameters**: `(Filter H * W * C_in + bias) * Num Filters`.
- **Cost**: Dominated by multiply-accumulate operations.
