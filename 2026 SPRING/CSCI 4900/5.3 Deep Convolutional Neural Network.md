```table-of-contents
```
# Intro
- comes from experiment:
## Hubel & Wiesel Experiment
- trying to understand how computer vision

# Neural basis of visual perception
- the point:
	- different neurons focus on different vision or pattern 
		- some focused on edges
		- some on colors
	- neurons have hierarchical structure
		- some handle low level
		- this neuron passes to next layer's neurons (higher level features)
			- each neuron only cares about small region

- based on this, people invent Convolution Neural Network
- this significantly improved the Computer Vision
- called LeNet

# LeNet
- has 2 convolutional layers
	- has subsampling layer
		- each trying to reduce intermediary result size
		- folded into fully connected layers

# Convolution Layer
- consider a 5x5x3 filter w
- this scans over entire 32x32x3 image (rgb)
- 1 neuron scans entire image and only captures a certain feature (where is the edge?)
	- another on color
	- another on ... (etc.)

- when neuron scans, it generates output feature map
	- this map is generated by:
		- starting from top left corner,  doing element-wise multiplication
			- (5x5x3 vals (rgb))
			- total of 5x5x3 multiplcations
			- accumulates number together to generate 1 output pixel for the feature map

## Second Filter -> Second Feature Map
- each filter, when scanning over input image, will generate 1 output feature map
	- 1st one generates only one channel, no matter what channels
- different filters generates diff filter maps
	- if 10 diff filters, 10 diff output feature maps
	- what is weight and height? depends on what the filter scanned

## Ex of Conv Layer
- Single filter sliding window
- Filter needs to have same number of channels as the input image channels (rgb = 3)
	- (black and white = 1 channel)
- after each element wise multiplication, it creates 1 output pixel of the feature map, then sliding window slides 1 element to right and repeats to create next output pixel of feature map

- input channel: input image
- output channel: the feature maps (activation maps)
- this output becomes the input channel of next layer:

	- *what is the filter size, if output maps is 28x28x6, and filter was 3x3x3?*
		**3x3x6, in order to reach all 6 z-depths (6 channels)**
	- you can determine the amount of filters in a layer by counting amount of channels 

- one filter is for finding face, eyes, nose, mouth, etc.
- during training, hard to control the job of each neuron, the neural network decides it itself
- in this way neural network is sort of like a black box

- output  neuron only connects to small region of input neuron
- that's b/c the neuron only cares about 1 small region 

## ConvNet
- ConvNet is a sequence of Convolution Layers followed by activation functions and pooling layers

## Features at Diff Layers
- Yellow Bus -> Low Level Feat -> Mid Level Feat -> High Level Feat -> Trainable Classifier

# Stride in Convolutional Layer
- Stride 1: move filter 1 to right
- 
- 7x7 input, 3x3 filter
	- what is output size if stride = 1?
		- 5x5 
	- How about Stride 2?
		- you move 2 to right instead (SKIP a pixel)
		- 3x3
	- Stride 3?
		- 2x2 
			- Problem 1: (it can't reach all pixels, they get lost)
			- Problem 2: we can't capture relationship
- Output size: (NputSize-FeatureMapSize) / stride + 1 (don't remember lol)


## Zero Padding
- common to zero pad the border
	- input 7x7, 3x3 filter, 1 pxl zero padding, what is output?
		- 7x7
	- what if you have a 5x5 filter? just add another layer of zero padding around border
- Conv layers w/ stride 1, filter size FxF, a


# **Size Calculation**
- input volume: 32x32x3, 10 5x5x3 filters w/ stride 1, pad 2 pixels, what is output volume size?
- What is num of params in this layer?
	- 5 +
- What is computation cost?

- num of params:
	- without bias: 
	- with bias: 

# Notes:
- number of feature maps depend on # of diff filters
- the final output is the collection of feature maps

- input channel: input image
- output channel: the feature maps (activation maps)
- this output becomes the input channel of next layer:
	- what is the filter size, if output maps is 28x28x6, and filter was 3x3x3?
		- **3x3x6, in order to reach all 6 z-depths (6 channels)**
- **how many filters is also a hyperparameter**


# Test
- Output size: (NputSize-FeatureMapSize) / stride + 1 (don't remember lol, just know the center)

- size calculation/ computation cost
	- output map size = 32x32 (b/c 5x5 filter with padding of 2!!) 
	- 10 channels (10 filters)
	- 10 parameters?
	- cost: 