```table-of-contents
```

# Intro - Machine Intelligence
- autonomous-driving
- speech
- translation
- recommendation
- robotics

## Why Machine Learning?
- Cognition, easy for human brain, hard for computers
	- Hard to program b/c we don't know how it works
	- Even if we do, program very complicated
	- Need to consider all kinds of input, app env, 
		- for a new task a new program must be written
- Human brain relies on memories and pattern matchmaking
	- Learn from past experiences
	- Adapt to new env and new tasks
## Machine Learning Approach
- we collect lots of examples that specify the correct ourpur for each given input
- a ML algorithm learns from these examples and produces a program (model) that does the job
	- If the learning is right, the program also works for new inputs that are not in the training set but share some similarity
	- For a new task, a new set of training data is needed, and a new model will be learned

[dog.img] ]Input -> **Model** -> Output "DOG"

## Machine Learning is Good At...
- **Recognizing patterns**
	- objects in real scenes
	- Facial identities or facial expressions
	- spoken word
- **Recognizing anomalies / unusual**
	- Unusual sequences of credit card transactions
	- Unusual patterns of sensor readings in a power plant
- **Prediction**
	- Future stock prices or currency exchange rates
		- **THIS IS NOT RELIABLE, too many variables and uncertainties***
		- *but predicting housing prices might be more suitable*
	- Which movies will a person like?

## Machine Learning is BAD At...
- **Correlation â‰  Causation**
	- ML finds patterns, not causes
		- A model finds that hospitals w/ more doctors have higher death rates
		- *Wrong conclusion:* Doctors cause deaths
- **Rare and Extreme Events**
	- ML struggles when data is scarce
	- Financial crisis
	- New pandemics
- **Value Judgements and Ethics**
	- ML cannot decide what is fair, ethical, or socially desirable

- Predicting Stock Prices, too many variables 
- Doing high-level math, especially w/ REASONING

# AL > ML > DL
- AI , then ML , then DL

- **AI**
	- broad field of creating systems or machines that can perform tasks typically requiring human intelligence

- **ML**
	- learning w/o explicit programming
	- focuses on development of algorithms and statistical models that allow computers to learn and make predictions or decisions w/o being explicitly programmed

- **DL**
	- ML that uses deep neural networks (DNN) **to model complex patterns in data**

## Deep Neural Network vs "Normal" Neural Network
- **deep neural network:**
	- multiple layers (>2 layers)
		- each w/ some parameter
			- each layer calcs something, sends intermediary result to next layer
	- neurons connect to a layer, or more
		- fully connected layer: all neurons in one layer connected to all neurons in another
- **normal neural network:**


# What enables Machine Learning?
- **Fast computers:**
	- GPU, TPU, NPU, accelerators ...
		- NVIDIA Titan X Pascal - 3840 Cuda core, 12 TFLOPS
		- NVIDIA RTX 4090, 16384 CUDA core, 512 TFLOPS, 82.6 TFLOPS
		- NVIDIA V100 - 640 TensorCores, 125 TFLOPS

- **CUDA Cores** - basic units inside GPU to compute floating point ops
	- general computing unit
	- Normally, in some computers, each core handles an operation
	- However, for CUDA Cores, <span style="background:#fff88f">each core is a CPU</span>

	- important for **Matrix Multiplication**
		- can divide MM into multiple steps
		- can do this in parallel
		- and combine result

- **FLOPS - Floating Point Ops Per Second**
	- TFLOPS - Tera
		- 10 ^ 12 floating point ops per sec
		- means how fast it can compute
- **FLOPs - Floating Points Operations**
	- complexity 

## GPUs vs TPUs

**GPUs:**
- excel at parallel processing
- versatile and widely adopted
	- 3080 and 3090 are most economic GPUs

**TPUs:**
- Google invented this, **a chip dedicated for computation of M.M.**
	- newest version is V7
- they invented this because:
	- **Super Optimized for Computation**
		- most other general GPUs have chips for rendering games, etc.
			- control logic can be complicated
		- *the TPU reduces overhead/power-consumption and removes redundancy for more efficiency*
	- Developing Chips is EXPENSIVE

## Tensor Cores vs CUDA Cores:
- Tensor Cores specialized for Higher-Dimensionality Tensor ops
	- *specifically for Deep Learning* 
	- Higher Dimension matrices are called Tensors

## Bottleneck: Data-movement
- High-end GPU server
## High-end GPU server
- HGX H100 8-GPU AI Server
	- top-tier hardware setup used **for training cutting-edge, extremely large-scale AI and deep learning models**
	- **$355,999**
	- Including Power-consumption (10KW) (10 microwaves) = $50/day
- *This immense power consumption is why Amazon builds new data centers place near power plant*

## Abundance of Data and Labeling Needed
- Abundant training data
	- **ImageNet**
		- over 10 mill urls of images have been hand-annotated to indicate objects in 1000 classes; at least one million of the images, bounding boxes are also provided
	- **MS Coco**
		- 328K Images of everyday scenes containing 91 types of common objects labeled using per-instance segmentations. 
		- w/ total of 2,5 million labeled instances
		- not perfect, since anyone can add image
	- **JFT-3B**
		- an internal Google dataset. It consists of nearly 3 billion images, annotated w/ a class-hierarchy of around 30k labels via a semi-automatic pipeline.
		- internal, so more accurate
			- for Vision
	- Flikr, Pascal VOC, Wikipedia
- You must have the right size of bounding box (very precise) for ML and DL to train on
- *GPT-3 uses an immense dataset (Common Crawl) of Internet-sourced data (570 gigabytes of text and 170 billion params), including text scraped from Wikipedia, Twitter, and Reddit. (~200 million words per GB)*

## Better models and training techniques
- Feed forward neural network
- Convolutional neural network
	- LeNet - 1995
	- AlexNet - 2012
	- VGG - 2014, ResNet - 2015
	- R-CNN - 2013, Fast R-CNN, Faster R-CNN, Mask - RCNN ...
	- YOLO - 2016, YOLO v2, v3, v4 ... v8

- Transformer-based neural network
	- **BERT** - 2018
		- handling text
	- **Vision Transformer** - 2021
	- GPT-1 (2018), 2 (2019), 3 (2020), 3.5 (2022), 4 (2023), 4o (2024), o1 (2024), 5 (2025)


# Intro - Neural Networks
- An emulation of biological neural systems
	- Paralle computation
	- Adaptive connections
- Very diff style from sequential computation
	- Should be good for things that brains are good at (e.g. vision)
	- Should be bad for things that brians are bat at (e.g., 23 x 71, calc can do better than brain)
		- this is still true
- To solve practical problems by using novel learning algorithms inspired by brain
	- Learning algorithms can be very useful even if they are not how the brain actually works

- Axons typically contact dendrites and ....

## Put everything together
- each neurons receives inputs from other neurons
	- few neurons also connect to receptors
	- cortical neurons use spikes to communicate
	- the effect of each input line on the neuron is controlled by synaptic weight
	- the weights can be positive or negative
	- the synaptic weights adapt so that the whole network learns to perform useful computations
		- Recognizing objects, understanding language, making plans, controlling the body
- You have about 10^11 neurons each w/ about 10^4 weights
	- A huge number of weights involve in the computation in a very short time. Much much higher bandwidth than a workstation

- even most powerful modern models have far simpler amounts of neurons/weights
- GPT has 10^9 neurons

## Neuron Models
- Idealized neuron models

## Linear Neurons
- These are simple but computationally limited
	- if we can make them learn we may get insight into more complicated neurons
	- y = b(bias) + SUM_i (x_i w_i)
- 

## Connecting Them Together
- Assume ReLU is used as the activation function
	- Output
		- Ex:
			- if this output node results in larger number, then this is a dog
			- if the other, then this is a cat
	- Inputs
		- pixel, each node at bottom is node 1, 2, 3, ...
- <span style="background:#fff88f">You can consider Neural Network as just a Computation Graph</span>
	- consists of lots of linear neurons


## Activation Function - Sigmoid Neurons
- These give a real-valued output that is a smooth and bounded function of their total input
	- Typically, they are used for the logistic function
- linear func
	- z = b + SUM_i (x_i w_i)
- non-linear func
	- y = 1 / 1+e^-z

- entire system can become non-linear func

## Activation Function - Hyperbolic Tagent (TanH)
- have same benefit as Sigmoid and also a zero mean output

## Activation Function - Rectified Linear Neurons ReLU
- one of most common ways to introduce non-linearity
- they compute a linear weighted sums
- The output is a non-linear function of the total input

z = b + SUM_i (x_i w_i)
y = 
1. z if z>0
2. 0 otherwise

- problems:
	- information loss
	- non-differentiable at 0
	- not zero-centered
	- unbounded


# Notes


# Vocab
- **FLOPS - Floating Point Ops Per Second**
- TFLOPS - Tera
	- 10 ^ 12 floating point ops per sec
- **FLOPs - Floating Points Operations**